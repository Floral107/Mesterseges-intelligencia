{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+5CxaS8bcom15zdK/v1gu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Floral107/Mesterseges-intelligencia/blob/main/housing_lab5_hf_neuralis_halo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feladat\n",
        "Ebben a házi feladatban a cél házak árának predikciója lesz neurális hálózat segítségével. Az eredeti adathalmaz innen származik. Itt található róla egy rövid leírás. A neurális hálózat segítségével a környékre jellemző különböző 8 jellemző alapján (medián jövedelem, házak korának átlaga, szobák átlagos száma, stb.) a házak értékének mediánját kell megbecsülni. A cél, hogy minél pontosabb legyen a becslés, amit MSE (mean squared error) alapján határozunk meg.\n",
        "\n",
        "Ehhez a megfelelő adathalmazt a moodle-ről lehet letölteni. Az adathalmaz linkje a moodle-ben a házi feladat alatt található a \"Dataset assignment\"-nél (ami egy 0 pontos quiz). Link a Moodle-höz\n",
        "Ugyanitt olvasható egy \"mse range\" intervallum is, amely a maximális és minimális pontszámhoz tartozó MSE értékeket jelöli. A kapott pontszámot ezek között lineáris, ezen kívül pedig nearest neighbor interpolációval határozzuk meg.\n",
        "\n",
        "A feladat tetszőleges környezetben megoldható. Mivel a területen a python a legelterjedtebb, ezért ehhez adunk segítséget."
      ],
      "metadata": {
        "id": "K2Zs8OKLFafc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQhRMmcd_rQD",
        "outputId": "03b908a1-9308-4ceb-fec2-4b8c855f70ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0113 - mean_squared_error: 0.0108 - val_loss: 0.0136 - val_mean_squared_error: 0.0131 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0113 - mean_squared_error: 0.0108 - val_loss: 0.0134 - val_mean_squared_error: 0.0129 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mean_squared_error: 0.0114 - val_loss: 0.0123 - val_mean_squared_error: 0.0118 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0114 - mean_squared_error: 0.0109 - val_loss: 0.0125 - val_mean_squared_error: 0.0120 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0112 - mean_squared_error: 0.0107 - val_loss: 0.0121 - val_mean_squared_error: 0.0117 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0115 - mean_squared_error: 0.0110 - val_loss: 0.0124 - val_mean_squared_error: 0.0119 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0119 - mean_squared_error: 0.0114 - val_loss: 0.0120 - val_mean_squared_error: 0.0114 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0112 - mean_squared_error: 0.0107 - val_loss: 0.0116 - val_mean_squared_error: 0.0111 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0115 - mean_squared_error: 0.0110 - val_loss: 0.0117 - val_mean_squared_error: 0.0112 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0109 - mean_squared_error: 0.0104 - val_loss: 0.0121 - val_mean_squared_error: 0.0116 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0112 - mean_squared_error: 0.0107 - val_loss: 0.0118 - val_mean_squared_error: 0.0113 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0110 - mean_squared_error: 0.0105 - val_loss: 0.0138 - val_mean_squared_error: 0.0133 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m353/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0115 - mean_squared_error: 0.0110\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0115 - mean_squared_error: 0.0110 - val_loss: 0.0119 - val_mean_squared_error: 0.0115 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0106 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0113 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0104 - mean_squared_error: 0.0100 - val_loss: 0.0115 - val_mean_squared_error: 0.0110 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0105 - mean_squared_error: 0.0100 - val_loss: 0.0114 - val_mean_squared_error: 0.0110 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0106 - mean_squared_error: 0.0102 - val_loss: 0.0115 - val_mean_squared_error: 0.0111 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0110 - mean_squared_error: 0.0106 - val_loss: 0.0116 - val_mean_squared_error: 0.0112 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0100 - mean_squared_error: 0.0096 - val_loss: 0.0114 - val_mean_squared_error: 0.0110 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m339/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - mean_squared_error: 0.0097\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0102 - mean_squared_error: 0.0097 - val_loss: 0.0116 - val_mean_squared_error: 0.0112 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0100 - mean_squared_error: 0.0096 - val_loss: 0.0114 - val_mean_squared_error: 0.0110 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0100 - mean_squared_error: 0.0096 - val_loss: 0.0113 - val_mean_squared_error: 0.0109 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0101 - mean_squared_error: 0.0097 - val_loss: 0.0112 - val_mean_squared_error: 0.0108 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0101 - mean_squared_error: 0.0097 - val_loss: 0.0112 - val_mean_squared_error: 0.0108 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0102 - mean_squared_error: 0.0098 - val_loss: 0.0111 - val_mean_squared_error: 0.0107 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0098 - mean_squared_error: 0.0093 - val_loss: 0.0113 - val_mean_squared_error: 0.0109 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0101 - mean_squared_error: 0.0096 - val_loss: 0.0112 - val_mean_squared_error: 0.0108 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m347/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - mean_squared_error: 0.0099\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0103 - mean_squared_error: 0.0099 - val_loss: 0.0112 - val_mean_squared_error: 0.0107 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0097 - mean_squared_error: 0.0092 - val_loss: 0.0113 - val_mean_squared_error: 0.0109 - learning_rate: 1.2500e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0102 - mean_squared_error: 0.0098 - val_loss: 0.0113 - val_mean_squared_error: 0.0109 - learning_rate: 1.2500e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0099 - mean_squared_error: 0.0095 - val_loss: 0.0112 - val_mean_squared_error: 0.0108 - learning_rate: 1.2500e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0098 - mean_squared_error: 0.0094 - val_loss: 0.0112 - val_mean_squared_error: 0.0108 - learning_rate: 1.2500e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m340/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0098 - mean_squared_error: 0.0094\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0099 - mean_squared_error: 0.0094 - val_loss: 0.0111 - val_mean_squared_error: 0.0107 - learning_rate: 1.2500e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0096 - mean_squared_error: 0.0092 - val_loss: 0.0112 - val_mean_squared_error: 0.0108 - learning_rate: 6.2500e-05\n",
            "Epoch 35/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0097 - mean_squared_error: 0.0093 - val_loss: 0.0111 - val_mean_squared_error: 0.0107 - learning_rate: 6.2500e-05\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0113 - mean_squared_error: 0.0108 - val_loss: 0.0117 - val_mean_squared_error: 0.0113 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0112 - mean_squared_error: 0.0107 - val_loss: 0.0124 - val_mean_squared_error: 0.0119 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0120 - mean_squared_error: 0.0115 - val_loss: 0.0113 - val_mean_squared_error: 0.0108 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0117 - mean_squared_error: 0.0112 - val_loss: 0.0114 - val_mean_squared_error: 0.0109 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0117 - mean_squared_error: 0.0112 - val_loss: 0.0117 - val_mean_squared_error: 0.0113 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0118 - mean_squared_error: 0.0113 - val_loss: 0.0119 - val_mean_squared_error: 0.0114 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0111 - mean_squared_error: 0.0106 - val_loss: 0.0120 - val_mean_squared_error: 0.0116 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m348/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - mean_squared_error: 0.0107\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0111 - mean_squared_error: 0.0107 - val_loss: 0.0115 - val_mean_squared_error: 0.0110 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0109 - mean_squared_error: 0.0104 - val_loss: 0.0111 - val_mean_squared_error: 0.0106 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0107 - mean_squared_error: 0.0103 - val_loss: 0.0109 - val_mean_squared_error: 0.0105 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0107 - mean_squared_error: 0.0102 - val_loss: 0.0110 - val_mean_squared_error: 0.0105 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0108 - mean_squared_error: 0.0103 - val_loss: 0.0110 - val_mean_squared_error: 0.0105 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0109 - mean_squared_error: 0.0104 - val_loss: 0.0114 - val_mean_squared_error: 0.0110 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0105 - mean_squared_error: 0.0101 - val_loss: 0.0112 - val_mean_squared_error: 0.0108 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m357/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0104 - mean_squared_error: 0.0100\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0104 - mean_squared_error: 0.0100 - val_loss: 0.0110 - val_mean_squared_error: 0.0105 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0103 - mean_squared_error: 0.0099 - val_loss: 0.0108 - val_mean_squared_error: 0.0104 - learning_rate: 2.5000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0102 - mean_squared_error: 0.0098 - val_loss: 0.0113 - val_mean_squared_error: 0.0109 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0104 - mean_squared_error: 0.0100 - val_loss: 0.0108 - val_mean_squared_error: 0.0104 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0103 - mean_squared_error: 0.0099 - val_loss: 0.0111 - val_mean_squared_error: 0.0107 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0102 - mean_squared_error: 0.0098 - val_loss: 0.0108 - val_mean_squared_error: 0.0104 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m337/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0100 - mean_squared_error: 0.0096\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0100 - mean_squared_error: 0.0097 - val_loss: 0.0110 - val_mean_squared_error: 0.0107 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0099 - mean_squared_error: 0.0095 - val_loss: 0.0109 - val_mean_squared_error: 0.0105 - learning_rate: 1.2500e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0101 - mean_squared_error: 0.0097 - val_loss: 0.0107 - val_mean_squared_error: 0.0103 - learning_rate: 1.2500e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0098 - mean_squared_error: 0.0094 - val_loss: 0.0108 - val_mean_squared_error: 0.0104 - learning_rate: 1.2500e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0097 - mean_squared_error: 0.0093 - val_loss: 0.0108 - val_mean_squared_error: 0.0105 - learning_rate: 1.2500e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0099 - mean_squared_error: 0.0095 - val_loss: 0.0109 - val_mean_squared_error: 0.0105 - learning_rate: 1.2500e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0099 - mean_squared_error: 0.0095 - val_loss: 0.0109 - val_mean_squared_error: 0.0105 - learning_rate: 1.2500e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m345/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0102 - mean_squared_error: 0.0098\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0102 - mean_squared_error: 0.0098 - val_loss: 0.0109 - val_mean_squared_error: 0.0105 - learning_rate: 1.2500e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0098 - mean_squared_error: 0.0094 - val_loss: 0.0108 - val_mean_squared_error: 0.0104 - learning_rate: 6.2500e-05\n",
            "Epoch 30/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0098 - mean_squared_error: 0.0094 - val_loss: 0.0108 - val_mean_squared_error: 0.0104 - learning_rate: 6.2500e-05\n",
            "Epoch 31/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0099 - mean_squared_error: 0.0095 - val_loss: 0.0108 - val_mean_squared_error: 0.0104 - learning_rate: 6.2500e-05\n",
            "Epoch 32/100\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0098 - mean_squared_error: 0.0094 - val_loss: 0.0109 - val_mean_squared_error: 0.0105 - learning_rate: 6.2500e-05\n",
            "Epoch 33/100\n",
            "\u001b[1m348/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0100 - mean_squared_error: 0.0096\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0100 - mean_squared_error: 0.0096 - val_loss: 0.0108 - val_mean_squared_error: 0.0104 - learning_rate: 6.2500e-05\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "[[2.4086998]\n",
            " [2.745581 ]\n",
            " [4.2329936]\n",
            " ...\n",
            " [4.487484 ]\n",
            " [2.9938745]\n",
            " [2.5299993]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "x_test = pd.read_csv(f'{\"housing_x_test_70efdf\"}.csv', sep=',', encoding='utf-8').values\n",
        "x_train = pd.read_csv(f'{\"housing_x_train_70efdf\"}.csv', sep=',', encoding='utf-8').values\n",
        "y_train = pd.read_csv(f'{\"housing_y_train_70efdf\"}.csv', sep=',', encoding='utf-8').values\n",
        "\n",
        "scaler_x = MinMaxScaler().fit(x_train)\n",
        "scaled_x_train = scaler_x.transform(x_train)\n",
        "scaled_x_test = scaler_x.transform(x_test)\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "scaled_y_train = scaler_y.fit_transform(y_train)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(scaled_x_train, scaled_y_train, test_size=0.2)\n",
        "\n",
        "#model\n",
        "def create_nn_model():\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
        "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
        "    model.add(tf.keras.layers.Dropout(0.3))  # Dropout for regularization\n",
        "    model.add(Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)))  # L2 Regularization\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return model\n",
        "\n",
        "# Train two neural network models\n",
        "model1 = create_nn_model()\n",
        "model1.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=0)\n",
        "\n",
        "model2 = create_nn_model()\n",
        "model2.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=0)\n",
        "\n",
        "# Korai leállás\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "# Tanulási ütem csökkentése\n",
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, verbose=1)\n",
        "\n",
        "# Modell betanítása\n",
        "history1 = model1.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val),\n",
        "                    callbacks=[early_stopping, lr_scheduler])\n",
        "\n",
        "y_test1 = model1.predict(scaled_x_test)\n",
        "\n",
        "histor2 = model2.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val),\n",
        "                    callbacks=[early_stopping, lr_scheduler])\n",
        "\n",
        "y_test2 = model2.predict(scaled_x_test)\n",
        "\n",
        "y_test = (y_test1 + y_test2) / 2\n",
        "y_test_rescaled = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "print(y_test_rescaled)\n",
        "\n",
        "np.savetxt('housing_y_test.csv', y_test_rescaled, delimiter=\",\", fmt=\"%g\")\n",
        "\n",
        "\n"
      ]
    }
  ]
}